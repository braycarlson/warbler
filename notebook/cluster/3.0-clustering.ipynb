{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9b2cd9",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "path = str(Path.cwd().parent)\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d02a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "from path import CWD, DATA\n",
    "from pathlib import Path\n",
    "from scipy.stats import zscore\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "from functions.plot_functions import umap_3Dplot, plotly_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9274221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions for calculating unadjusted Rand score\n",
    "# Resource: https://stackoverflow.com/questions/49586742/rand-index-function-clustering-performance-evaluation\n",
    "\n",
    "def rand_index_score(clusters, classes):\n",
    "    tp_plus_fp = scipy.special.comb(np.bincount(clusters), 2).sum()\n",
    "    tp_plus_fn = scipy.special.comb(np.bincount(classes), 2).sum()\n",
    "    A = np.c_[(clusters, classes)]\n",
    "    tp = sum(scipy.special.comb(np.bincount(A[A[:, 0] == i, 1]), 2).sum() for i in set(clusters))\n",
    "    fp = tp_plus_fp - tp\n",
    "    fn = tp_plus_fn - tp\n",
    "    tn = scipy.special.comb(len(A), 2) - tp - fp - fn\n",
    "    return (tp + tn) / (tp + fp + fn + tn)\n",
    "\n",
    "\n",
    "def calc_rand(pred, true):\n",
    "    classnames, pred = np.unique(pred, return_inverse=True)\n",
    "    classnames, true = np.unique(true, return_inverse=True)\n",
    "    return rand_index_score(pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a1ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_colors_22 = [\n",
    "    '#e6194b',\n",
    "    '#3cb44b',\n",
    "    '#ffe119',\n",
    "    '#4363d8',\n",
    "    '#f58231',\n",
    "    '#911eb4',\n",
    "    '#46f0f0',\n",
    "    '#f032e6',\n",
    "    '#bcf60c',\n",
    "    '#fabebe',\n",
    "    '#008080',\n",
    "    '#e6beff',\n",
    "    '#9a6324',\n",
    "    '#fffac8',\n",
    "    '#800000',\n",
    "    '#aaffc3',\n",
    "    '#808000',\n",
    "    '#ffd8b1',\n",
    "    '#000075',\n",
    "    '#808080',\n",
    "    '#ffffff',\n",
    "    '#000000'\n",
    "]\n",
    "\n",
    "# Column name of label variable\n",
    "LABEL_COL = 'label'\n",
    "\n",
    "# Load dataframe with UMAP coordinates\n",
    "pkl = DATA.joinpath('df_umap.pkl')\n",
    "df = pd.read_pickle(pkl)\n",
    "\n",
    "# Detect columns with UMAP coordinates\n",
    "UMAP_COLS = [x for x in df.columns if 'UMAP' in x]\n",
    "\n",
    "# Save labels and embedding as variables\n",
    "\n",
    "# labels\n",
    "labels = df[LABEL_COL]\n",
    "\n",
    "# UMAP coordinates\n",
    "embedding = np.asarray(df[UMAP_COLS])\n",
    "\n",
    "print(f\"Found: {len(UMAP_COLS)} UMAP columns. Label in column: {LABEL_COL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "HDBSCAN = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=int(0.01 * embedding.shape[0]),\n",
    "    cluster_selection_method='leaf'\n",
    ").fit(embedding)\n",
    "\n",
    "# These are the predicted clusters labels\n",
    "hdb_labels = HDBSCAN.labels_\n",
    "\n",
    "# Add predicted cluster labels to dataframe\n",
    "df['HDBSCAN'] = hdb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198fe62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some evaluations, it makes sense to remove the datapoints labelled as noise\n",
    "# \"Noise\" datapoints are by default labelled as -1 by HDBSCAN\n",
    "\n",
    "hdb_labels_no_noise = hdb_labels.copy()\n",
    "assigned = np.full(\n",
    "    (len(hdb_labels_no_noise), ),\n",
    "    False\n",
    ")\n",
    "\n",
    "assigned[\n",
    "    np.where(hdb_labels_no_noise != -1)[0]\n",
    "] = True\n",
    "\n",
    "# the predicted cluster labels without noise datapoints\n",
    "hdb_labels_no_noise = hdb_labels_no_noise[assigned]\n",
    "\n",
    "# The dataframe without noise datapoints\n",
    "df_no_noise = df.loc[assigned]\n",
    "\n",
    "# The UMAP coordinates without noise datapoints\n",
    "embedding_no_noise = embedding[assigned, :]\n",
    "\n",
    "\n",
    "# evaluate clustering\n",
    "\n",
    "print(\"************************\")\n",
    "print(\"HDBSCAN:\")\n",
    "print(\"************************\")\n",
    "cluster_labels = hdb_labels\n",
    "true_labels = df[LABEL_COL]\n",
    "embedding_data = embedding\n",
    "\n",
    "\n",
    "print(f\"RI: {calc_rand(cluster_labels, true_labels)}\")\n",
    "print(f\"ARI: {adjusted_rand_score(cluster_labels, true_labels)}\")\n",
    "print(f\"SIL: {silhouette_score(embedding_data, cluster_labels)}\")\n",
    "print(f\"N_clust: {len(list(set(cluster_labels)))}\")\n",
    "\n",
    "print(\"************************\")\n",
    "print(\"HDBSCAN-no-noise:\")\n",
    "print(\"************************\")\n",
    "cluster_labels = hdb_labels_no_noise\n",
    "true_labels = df_no_noise[LABEL_COL]\n",
    "embedding_data = embedding_no_noise\n",
    "\n",
    "\n",
    "print(f\"RI: {calc_rand(cluster_labels, true_labels)}\")\n",
    "print(f\"ARI: {adjusted_rand_score(cluster_labels, true_labels)}\")\n",
    "print(f\"SIL: {silhouette_score(embedding_data, cluster_labels)}\")\n",
    "print(f\"N_clust: {len(list(set(cluster_labels)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_colors = ['#d9d9d9'] + distinct_colors_22\n",
    "\n",
    "umap_3Dplot(\n",
    "    # x-axis coordinates\n",
    "    x=df['UMAP1'],\n",
    "    # y-axis coordinates\n",
    "    y=df['UMAP2'],\n",
    "    # z-axis coordinates\n",
    "    z=df['UMAP3'],\n",
    "    # labels (if available)\n",
    "    scat_labels=hdb_labels,\n",
    "    # sns.Palette color scheme name or list of colors\n",
    "    mycolors=hdb_colors,\n",
    "    # filename (with path) where figure will be saved.\n",
    "    # Default: None -> figure not saved\n",
    "    outname=None,\n",
    "    # show legend if True else no legend\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "umap_3Dplot(\n",
    "    # x-axis coordinates\n",
    "    x=df['UMAP1'],\n",
    "    # y-axis coordinates\n",
    "    y=df['UMAP2'],\n",
    "    # z-axis coordinates\n",
    "    z=df['UMAP3'],\n",
    "    # labels (if available)\n",
    "    scat_labels=labels,\n",
    "    # sns.Palette color scheme name or list of colors\n",
    "    mycolors=distinct_colors_22,\n",
    "    # filename (with path) where figure will be saved.\n",
    "    # Default: None -> figure not saved\n",
    "    outname=CWD.joinpath('map.png'),\n",
    "    # show legend if True else no legend\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab37a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column name of spectrogram to display\n",
    "# (denoised_spectrograms, spectrograms...)\n",
    "DISPLAY_COL = 'spectrograms'\n",
    "\n",
    "n_specs = 5\n",
    "\n",
    "clusters = sorted(\n",
    "    list(\n",
    "        set(hdb_labels)\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(\n",
    "    n_specs * 2,\n",
    "    len(clusters) * 2)\n",
    ")\n",
    "\n",
    "k = 1\n",
    "specs = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    example = df[df['HDBSCAN'] == cluster].sample(\n",
    "        n=n_specs,\n",
    "        random_state=2204\n",
    "    )\n",
    "    specs = example[DISPLAY_COL].values\n",
    "    labels = example[LABEL_COL].values\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    plt.subplot(\n",
    "        len(clusters),\n",
    "        n_specs + 1,\n",
    "        k\n",
    "    )\n",
    "\n",
    "    k += 1\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.text(\n",
    "        0.5,\n",
    "        0.4,\n",
    "        'Cl. ' + str(cluster),\n",
    "        fontsize=16\n",
    "    )\n",
    "\n",
    "    for spec, label in zip(specs, labels):\n",
    "        plt.subplot(len(clusters), n_specs + 1, k)\n",
    "        plt.imshow(\n",
    "            spec,\n",
    "            interpolation='nearest',\n",
    "            aspect='equal',\n",
    "            origin='lower'\n",
    "        )\n",
    "        plt.axis('off')\n",
    "        title = str(label)\n",
    "        plt.title(title)\n",
    "        k += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Column name of variable by which to analyze cluster content.\n",
    "# Select any variable of interest in DF\n",
    "analyze_by = LABEL_COL\n",
    "\n",
    "# Variable of cluster labels\n",
    "cluster_labels = hdb_labels\n",
    "\n",
    "cluster_labeltypes = sorted(\n",
    "    list(\n",
    "        set(cluster_labels)\n",
    "    )\n",
    ")\n",
    "\n",
    "by_types = sorted(\n",
    "    list(\n",
    "        set(df[analyze_by])\n",
    "    )\n",
    ")\n",
    "\n",
    "stats_tab = np.zeros(\n",
    "    (\n",
    "        len(cluster_labeltypes),\n",
    "        len(by_types)\n",
    "    )\n",
    ")\n",
    "\n",
    "for i, clusterlabel in enumerate(cluster_labeltypes):\n",
    "    label_df = df.loc[cluster_labels == clusterlabel]\n",
    "\n",
    "    for j, by_type in enumerate(by_types):\n",
    "        stats_tab[i, j] = sum(label_df[analyze_by] == by_type)\n",
    "\n",
    "stats_tab_df = pd.DataFrame(\n",
    "    stats_tab,\n",
    "    index=cluster_labeltypes,\n",
    "    columns=by_types\n",
    ")\n",
    "\n",
    "# absolute vals\n",
    "plt.figure(\n",
    "    figsize=(\n",
    "        int(len(cluster_labeltypes) / 2),\n",
    "        int(len(by_types))\n",
    "    )\n",
    ")\n",
    "ax = sns.heatmap(\n",
    "    stats_tab_df,\n",
    "    annot=True,\n",
    "    cmap='viridis',\n",
    "    fmt='.0f',\n",
    "    cbar=False\n",
    ")\n",
    "ax.set_xlabel(analyze_by, fontsize=16)\n",
    "ax.set_ylabel(\"Cluster label\", fontsize=16)\n",
    "ax.tick_params(labelsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rowsums\n",
    "stats_tab_norm = np.zeros(\n",
    "    (stats_tab.shape)\n",
    ")\n",
    "rowsums = np.sum(stats_tab, axis=1)\n",
    "\n",
    "for i in range(stats_tab.shape[0]):\n",
    "    stats_tab_norm[i, :] = stats_tab[i, :] / rowsums[i]\n",
    "\n",
    "stats_tab_norm_df = pd.DataFrame(\n",
    "    stats_tab_norm,\n",
    "    index=cluster_labeltypes,\n",
    "    columns=by_types\n",
    ") * 100\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(\n",
    "        int(len(cluster_labeltypes) / 2),\n",
    "        int(len(by_types))\n",
    "    )\n",
    ")\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    stats_tab_norm_df,\n",
    "    annot=True,\n",
    "    cmap='viridis',\n",
    "    fmt='.1f',\n",
    "    cbar=False\n",
    ")\n",
    "\n",
    "ax.set_xlabel(analyze_by, fontsize=16)\n",
    "ax.set_ylabel(\"Cluster label\", fontsize=16)\n",
    "ax.tick_params(labelsize=16)\n",
    "\n",
    "\n",
    "# Colsums\n",
    "stats_tab_norm = np.zeros(\n",
    "    (stats_tab.shape)\n",
    ")\n",
    "colsums = np.sum(stats_tab, axis=0)\n",
    "\n",
    "for i in range(stats_tab.shape[1]):\n",
    "    stats_tab_norm[:, i] = stats_tab[:, i] / colsums[i]\n",
    "\n",
    "stats_tab_norm_df = pd.DataFrame(\n",
    "    stats_tab_norm,\n",
    "    index=cluster_labeltypes,\n",
    "    columns=by_types\n",
    ") * 100\n",
    "\n",
    "plt.figure(\n",
    "    figsize=(\n",
    "        int(len(cluster_labeltypes) / 2),\n",
    "        int(len(by_types))\n",
    "    )\n",
    ")\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    stats_tab_norm_df,\n",
    "    annot=True,\n",
    "    cmap='viridis',\n",
    "    fmt='.1f',\n",
    "    cbar=False\n",
    ")\n",
    "\n",
    "ax.set_xlabel(analyze_by, fontsize=16)\n",
    "ax.set_ylabel(\"Cluster label\", fontsize=16)\n",
    "ax.tick_params(labelsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

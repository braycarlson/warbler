{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afcd846",
   "metadata": {},
   "source": [
    "# Segment\n",
    "\n",
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c422b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "path = str(Path.cwd().parent)\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9274221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from avgn.dataset import DataSet\n",
    "from avgn.signalprocessing.create_spectrogram_dataset import (\n",
    "    create_label_df,\n",
    "    get_row_audio,\n",
    "    log_resize_spec,\n",
    "    make_spec,\n",
    "    pad_spectrogram,\n",
    ")\n",
    "from avgn.utils.hparams import HParams\n",
    "from avgn.visualization.spectrogram import draw_spec_set\n",
    "from parameters import PARAMETERS\n",
    "from joblib import Parallel, delayed\n",
    "from path import INDIVIDUALS\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb06a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional]\n",
    "# Normalize the spectrograms into uint8\n",
    "# This will make the dataset smaller\n",
    "def norm(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "\n",
    "# Create a set of parameters for processing the dataset\n",
    "hparams = HParams(\n",
    "    n_fft=PARAMETERS.get('n_fft'),\n",
    "    hop_length_ms=PARAMETERS.get('hop_length_ms'),\n",
    "    win_length_ms=PARAMETERS.get('win_length_ms'),\n",
    "    ref_level_db=PARAMETERS.get('ref_level_db'),\n",
    "    pre=PARAMETERS.get('pre'),\n",
    "    min_level_db=PARAMETERS.get('min_level_db'),\n",
    "    min_level_db_floor=PARAMETERS.get('min_level_db_floor'),\n",
    "    db_delta=PARAMETERS.get('db_delta'),\n",
    "    silence_threshold=PARAMETERS.get('silence_threshold'),\n",
    "    min_silence_for_spec=PARAMETERS.get('min_silence_for_spec'),\n",
    "    max_vocal_for_spec=PARAMETERS.get('max_vocal_for_spec'),\n",
    "    min_syllable_length_s=PARAMETERS.get('min_syllable_length_s'),\n",
    "    spectral_range=PARAMETERS.get('spectral_range'),\n",
    "\n",
    "    num_mel_bins=PARAMETERS.get('num_mel_bins'),\n",
    "    mel_lower_edge_hertz=PARAMETERS.get('mel_lower_edge_hertz'),\n",
    "    mel_upper_edge_hertz=PARAMETERS.get('mel_upper_edge_hertz'),\n",
    "    butter_lowcut=PARAMETERS.get('butter_lowcut'),\n",
    "    butter_highcut=PARAMETERS.get('butter_highcut'),\n",
    "    mask_spec=PARAMETERS.get('mask_spec'),\n",
    "    nex=PARAMETERS.get('nex'),\n",
    "    n_jobs=PARAMETERS.get('n_jobs'),\n",
    "    verbosity=PARAMETERS.get('verbosity')\n",
    ")\n",
    "\n",
    "dataset = DataSet(INDIVIDUALS, hparams=hparams)\n",
    "\n",
    "n_jobs = PARAMETERS.get('n_jobs')\n",
    "verbosity = PARAMETERS.get('verbosity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a956e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "    syllable_dfs = parallel(\n",
    "        delayed(create_label_df)(\n",
    "            dataset.data_files[key].data,\n",
    "            hparams=dataset.hparams,\n",
    "            labels_to_retain=[\"labels\", \"sequence_num\"],\n",
    "            unit=\"notes\",\n",
    "            dict_features_to_retain=[],\n",
    "            key=key,\n",
    "        )\n",
    "        for key in tqdm(dataset.data_files.keys())\n",
    "    )\n",
    "\n",
    "syllable_df = pd.concat(syllable_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc09715",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "    syllable_dfs = parallel(\n",
    "        delayed(get_row_audio)(\n",
    "            syllable_df[syllable_df.key == key],\n",
    "            dataset.data_files[key].data['wav_loc'],\n",
    "            dataset.hparams\n",
    "        )\n",
    "        for key in tqdm(syllable_df.key.unique())\n",
    "    )\n",
    "\n",
    "syllable_df = pd.concat(syllable_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of syllables that are zero seconds,\n",
    "# which will produce errors in segmentation\n",
    "df_mask = np.array(\n",
    "    [len(i) > 0 for i in tqdm(syllable_df.audio.values)]\n",
    ")\n",
    "syllable_df = syllable_df[np.array(df_mask)]\n",
    "\n",
    "\n",
    "syllable_df['audio'] = [\n",
    "    librosa.util.normalize(i) for i in syllable_df.audio.values\n",
    "]\n",
    "\n",
    "# Plot some example audio\n",
    "nrows = 5\n",
    "ncols = 10\n",
    "zoom = 2\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=ncols,\n",
    "    nrows=nrows,\n",
    "    figsize=(ncols * zoom, nrows + zoom / 1.5)\n",
    ")\n",
    "\n",
    "for i, syll in tqdm(enumerate(syllable_df['audio'].values), total=nrows*ncols):\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.plot(syll)\n",
    "\n",
    "    if i == nrows * ncols - 1:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40882d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "    # Create spectrograms\n",
    "    syllables_spec = parallel(\n",
    "        delayed(make_spec)(\n",
    "            syllable,\n",
    "            rate,\n",
    "            hparams=dataset.hparams,\n",
    "            mel_matrix=dataset.mel_matrix,\n",
    "            use_mel=True,\n",
    "            use_tensorflow=False,\n",
    "        )\n",
    "        for syllable, rate in tqdm(\n",
    "            zip(syllable_df.audio.values, syllable_df.rate.values),\n",
    "            total=len(syllable_df),\n",
    "            desc=\"Getting syllable spectrograms\",\n",
    "            leave=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "plt.matshow(syllables_spec[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A hyperparameter where larger = higher dimensional spectrogram\n",
    "log_scaling_factor = 10\n",
    "\n",
    "with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "    syllables_spec = parallel(\n",
    "        delayed(log_resize_spec)(spec, scaling_factor=log_scaling_factor)\n",
    "        for spec in tqdm(\n",
    "            syllables_spec,\n",
    "            desc=\"scaling spectrograms\",\n",
    "            leave=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Lets take a look at these spectrograms\n",
    "draw_spec_set(\n",
    "    syllables_spec,\n",
    "    zoom=1,\n",
    "    maxrows=10,\n",
    "    colsize=25\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "syllables_spec = [\n",
    "    (norm(i) * 255).astype('uint8') for i in tqdm(syllables_spec)\n",
    "]\n",
    "\n",
    "syll_lens = [np.shape(i)[1] for i in syllables_spec]\n",
    "plt.hist(syll_lens)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "pad_length = np.max(syll_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912719cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "    syllables_spec = parallel(\n",
    "        delayed(pad_spectrogram)(spec, pad_length)\n",
    "        for spec in tqdm(\n",
    "            syllables_spec, desc=\"padding spectrograms\", leave=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "draw_spec_set(syllables_spec, zoom=1, maxrows=10, colsize=25)\n",
    "plt.show()\n",
    "\n",
    "# What is the dimensionality of the dataset\n",
    "print(np.shape(syllables_spec))\n",
    "\n",
    "# convert to uint8 to save space\n",
    "syllables_spec = [\n",
    "    (norm(i) * 255).astype('uint8') for i in tqdm(syllables_spec)\n",
    "]\n",
    "\n",
    "syllable_df['spectrogram'] = syllables_spec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adelaideswarbler",
   "language": "python",
   "name": "adelaideswarbler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
